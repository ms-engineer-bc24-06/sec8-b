import os
import logging
import aiohttp
import asyncio
from openai import OpenAI
from sqlalchemy.orm import Session
from app.database import SessionLocal, init_db
from app.models import ConversationHistory
import asyncio
from .get_user_conversation import get_user_conversation_history

# ãƒ­ã‚¬ãƒ¼ã®è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# APIã‚­ãƒ¼ã‚’è¨­å®š
api_key = os.getenv("OPENAI_API_KEY")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã®å®šç¾©
drug_name = "ãƒ­ã‚­ã‚½ãƒ—ãƒ­ãƒ•ã‚§ãƒ³"
info_type = "ä½¿ã„æ–¹"
pmda_url = "https://www.pmda.go.jp/PmdaSearch/iyakuSearch/"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®å–å¾—ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ“ä½œã‚’è¡Œã†ãŸã‚ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³
# def get_db_session() -> Session:
#     return SessionLocal()

# ä¼šè©±å±¥æ­´ã‚’å–å¾—ã™ã‚‹é–¢æ•°
# def get_user_conversation_history(db: Session, user_id: str):
#     return db.query(ConversationHistory).filter(ConversationHistory.user_id == user_id).all()

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_prompt(drug_name: str, info_type: str, pmda_url: str) -> str:
    logger.info(f"ðŸ’ŠGenerating prompt for drug: {drug_name}, info type: {info_type}")
    return (f"è–¬å‰¤å: {drug_name}\n"
            f"çŸ¥ã‚ŠãŸã„æƒ…å ±: {info_type}\n"
            f"ä»¥ä¸‹ã®PMDAã®URLã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è–¬ã«ã¤ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ã‹ã‚Šã‚„ã™ã„èª¬æ˜Žã‚’ã—ã¦ãã ã•ã„ã€‚\n"
            f"URL: {pmda_url}")

# useridã§ä¼šè©±å±¥æ­´ã‚’å–å¾—ã™ã‚‹å‡¦ç†
# async def get_conversation_history(user_id):
#     # user_id = "Ufcb5e01230d0a1f9bbac8dbd9c1310d8"
#     try:
#         async with aiohttp.ClientSession() as session:
#             async with session.get(f"http://localhost:8000/api/conversation/{user_id}", timeout=10) as response:
#                 if response.status == 200:
#                     logger.info("ðŸ™†ä¼šè©±å±¥æ­´ãŒæ­£å¸¸ã«å–å¾—ã•ã‚Œã¾ã—ãŸã€‚")
#                     data = await response.json()
#                     logger.info(f"â—† ä¼šè©±å±¥æ­´: {data}")
#                     return data
#                 else:
#                     logger.error(f"ðŸ™…ä¼šè©±å±¥æ­´ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {response.status} - {await response.text()}")
#     except Exception as e:
#         logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")

# ä¼šè©±å±¥æ­´ã‚’åŸºã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
def generate_prompt_with_history(drug_name: str, info_type: str, pmda_url: str, user_id: str) -> str:

    pre_conversation_history = get_user_conversation_history(user_id)

    # ä¼šè©±å±¥æ­´ã‚’æ–‡å­—åˆ—ã«å¤‰æ›
    if not pre_conversation_history:
        conversation_history = "éŽåŽ»ã®ä¼šè©±å±¥æ­´ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚"
    else:
        conversation_history = '\n'.join(
            f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: {conv.user_message}\nãƒœãƒƒãƒˆ: {conv.bot_response}" for conv in pre_conversation_history
        )


    return (f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®éŽåŽ»ã®ä¼šè©±:\n{conversation_history}\n"
            f"è–¬å‰¤å: {drug_name}\n"
            f"çŸ¥ã‚ŠãŸã„æƒ…å ±: {info_type}\n"
            f"ä»¥ä¸‹ã®PMDAã®URLã‹ã‚‰å¾—ã‚‰ã‚Œã‚‹æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è–¬ã«ã¤ã„ã¦ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ã‹ã‚Šã‚„ã™ã„èª¬æ˜Žã‚’ã—ã¦ãã ã•ã„ã€‚\n"
            f"URL: {pmda_url}")


# æŒ‡å®šã—ãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åŸºã«ã€OpenAI GPTã‹ã‚‰ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’éžåŒæœŸã«å–å¾—ã™ã‚‹é–¢æ•°
def generate_natural_language_response(prompt: str, model: str = "gpt-4") -> str:
    logger.info("Generating response based on the provided prompt.")
    client = OpenAI(api_key=api_key)
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ],
        max_tokens=500,  # æœ€å¤§500ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ã®å¿œç­”
        temperature=0.5,  # å€¤ãŒ0ã«è¿‘ã„ã»ã©ã€ãƒ¢ãƒ‡ãƒ«ã¯ã‚ˆã‚Šæ±ºå®šçš„ãªå¿œç­”ã‚’ç”Ÿæˆ
        top_p=1  # ã™ã¹ã¦ã®ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è€ƒæ…®ã™ã‚‹
    )
    return response.choices[0].message.content.strip()

# check_relevance: å¿œç­”ãŒè–¬å“ã«é–¢é€£ã—ã¦ã„ã‚‹ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹
def check_relevance(response: str) -> str:
    logger.info(f"Checking relevance of response: {response}")
    if "è–¬" in response or "å‰¯ä½œç”¨" in response or "ä½¿ã„æ–¹" in response:
        return response
    else:
        logger.warning("Response is not relevant to the drug")
        return "è–¬å“ä»¥å¤–ã®è³ªå•ã«ã¯å›žç­”ã§ãã¾ã›ã‚“ã€‚"

# è–¬å‰¤ã«é–¢ã™ã‚‹æƒ…å ±ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_drug_info(drug_name: str, info_type: str, pmda_url: str, user_id:str, model: str = "gpt-4" ) -> str:
    # logger.info(f"â—† drug_info: {drug_name}")
    # logger.info(f"â—† info_type: {info_type}")
    # logger.info(f"â—† user_id: {user_id}")
    prompt = generate_prompt_with_history(drug_name, info_type, pmda_url , user_id)
    logger.info(f"â—† prompt: {prompt}")
    response = generate_natural_language_response(prompt, model)
    return response

# ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
def test_generate_prompt_with_history():
    drug_name = "ã‚¢ã‚¹ãƒ”ãƒªãƒ³"
    info_type = "å‰¯ä½œç”¨"
    pmda_url = "https://www.pmda.go.jp/"
    user_id = "haruka_ku-min_meme"
    
    prompt = generate_prompt_with_history(drug_name, info_type, pmda_url, user_id)
    print(prompt)

if __name__ == "__main__":
    test_generate_prompt_with_history()
